version: '3.8'

services:
  scrapper:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: scrapper
    ports:
      - "3000:3000"
    depends_on:
      - redis
    environment:
      - HOST=0.0.0.0
      - PORT=3000
      - LOG_LEVEL=info
      - BROWSER_TYPE=firefox
      - BROWSER_CONTEXT_LIMIT=20
      - SCREENSHOT_TYPE=jpeg
      - SCREENSHOT_QUALITY=80
      - UVICORN_WORKERS=5
      - DEBUG=false
      - REDIS_URL=redis://redis:6379/0
      - REDIS_ENABLED=true
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=gpt-4.1-mini
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/misc/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  redis:
    image: redis:7-alpine
    container_name: scrapper-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: scrapper-worker
    depends_on:
      - redis
      - scrapper
    environment:
      - LOG_LEVEL=info
      - BROWSER_TYPE=firefox
      - REDIS_URL=redis://redis:6379/0
      - REDIS_ENABLED=true
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=gpt-4.1-mini
    command: ["python", "worker_deep_scrape.py"]
    working_dir: /home/pwuser/app
    restart: unless-stopped
    volumes:
      - ./app:/home/pwuser/app
    healthcheck:
      test: ["CMD", "python", "-c", "import redis; r=redis.from_url('redis://redis:6379/0'); r.ping()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

volumes:
  redis_data: